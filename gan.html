<!doctype html>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Generative Adversarial Networks â€” Towards Generative Image AI</title>
<meta name="description" content="Discover the adversarial game between Generator and Discriminator â€” minimax optimization, Jensen-Shannon divergence, and mode collapse.">

<!-- Distill Template -->
<script src="https://distill.pub/template.v1.js"></script>

<!-- jQuery for loading header -->
<script src="https://code.jquery.com/jquery-3.6.0.min.js"></script>

<!-- MathJax for rendering equations -->
<script>
  MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']],
      displayMath: [['$$', '$$'], ['\\[', '\\]']],
      tags: 'ams'
    }
  };
</script>
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

<link rel="stylesheet" href="styles.css">

<style>
    /* â”€â”€ Global custom styles â”€â”€ */
    .interactive-container {
        border: 1px solid rgba(0,0,0,0.1);
        border-radius: 8px;
        background: #f9f9f9;
        padding: 24px;
        margin: 2rem 0;
        display: flex;
        flex-direction: column;
        align-items: center;
        font-family: 'Helvetica Neue', Helvetica, Arial, sans-serif;
    }
    .interactive-container h4 {
        margin: 0 0 12px;
        font-size: 14px;
        text-transform: uppercase;
        letter-spacing: 1px;
        color: #888;
    }
    .canvas-wrapper {
        position: relative;
        box-shadow: 0 4px 6px rgba(0,0,0,0.1);
        background: white;
        border-radius: 4px;
        overflow: hidden;
    }
    .control-panel {
        margin-top: 14px;
        font-size: 0.9em;
        color: #555;
        text-align: center;
        max-width: 640px;
    }

    /* â”€â”€ Alignment fixes â”€â”€ */
    dt-article .interactive-container,
    dt-article .intuition-box,
    dt-article .derivation-step {
      width: 100%;
      max-width: 760px;
      margin-left: auto;
      margin-right: auto;
      box-sizing: border-box;
    }
    dt-article .MathJax_Display,
    dt-article mjx-container[display="true"] {
      text-align: center;
      margin-left: auto !important;
      margin-right: auto !important;
    }

    /* â”€â”€ Derivation steps â”€â”€ */
    .derivation-step {
        background: #f4f8fb;
        border-left: 4px solid #EBC043;
        padding: 16px 20px;
        margin: 1.2rem 0;
        border-radius: 0 6px 6px 0;
    }
    .derivation-step .step-label {
        font-weight: 700;
        color: #EBC043;
        font-size: 0.85em;
        text-transform: uppercase;
        letter-spacing: 0.5px;
        margin-bottom: 6px;
    }

    /* â”€â”€ Intuition callout boxes â”€â”€ */
    .intuition-box {
        background: #fffbe6;
        border: 1px solid #EBC043;
        border-radius: 8px;
        padding: 16px 20px;
        margin: 1.5rem 0;
    }
    .intuition-box::before {
        content: 'ğŸ’¡ Intuition';
        display: block;
        font-weight: 700;
        font-size: 0.85em;
        color: #b8941e;
        margin-bottom: 6px;
    }

    /* â”€â”€ Buttons â”€â”€ */
    button.train-btn {
        padding: 10px 20px;
        font-size: 14px;
        font-weight: bold;
        border: none;
        border-radius: 4px;
        cursor: pointer;
        transition: transform 0.1s, opacity 0.2s;
    }
    button.train-btn:active { transform: scale(0.96); }
    .btn-d { background-color: #1a1a2e; color: white; }
    .btn-g { background-color: #c4922a; color: white; }
    .btn-reset { background-color: #e5e7eb; color: #374151; }
    .btn-play { background-color: #EBC043; color: #1a1a2e; }
    .btn-stop { background-color: #c4922a; color: white; }
    .btn-row {
        display: flex;
        gap: 10px;
        margin-top: 12px;
        align-items: center;
        flex-wrap: wrap;
        justify-content: center;
    }

    .status-text {
        margin-top: 10px;
        font-style: italic;
        color: #666;
        min-height: 20px;
        text-align: center;
    }

    .legend {
        display: flex;
        gap: 15px;
        font-size: 12px;
        margin-bottom: 10px;
        color: #444;
    }
    .legend span { display: flex; align-items: center; gap: 4px; }
    .dot { width: 10px; height: 10px; border-radius: 50%; display: inline-block; }

    /* â”€â”€ Slider rows â”€â”€ */
    .slider-row {
        display: flex;
        align-items: center;
        gap: 12px;
        margin: 8px 0;
        flex-wrap: wrap;
        justify-content: center;
    }
    .slider-row label {
        font-weight: 600;
        min-width: 120px;
        text-align: right;
    }
    .slider-row input[type=range] {
        width: 240px;
        accent-color: #EBC043;
    }
    .slider-row .val {
        min-width: 50px;
        font-family: monospace;
    }

    /* â”€â”€ Side-by-side panels â”€â”€ */
    .side-panels {
        display: flex;
        gap: 24px;
        flex-wrap: wrap;
        justify-content: center;
    }
    .side-panels .panel {
        text-align: center;
    }
    .side-panels .panel canvas {
        border: 1px solid #ccc;
        border-radius: 4px;
    }
    .side-panels .panel-label {
        font-weight: 600;
        margin-bottom: 8px;
        font-size: 0.95em;
    }

    /* â”€â”€ Epoch counter â”€â”€ */
    .epoch-display {
        font-family: monospace;
        font-size: 14px;
        background: #eee;
        padding: 4px 12px;
        border-radius: 4px;
    }

    /* â”€â”€ Loss chart â”€â”€ */
    .loss-wrapper {
        margin-top: 12px;
    }
    .loss-wrapper canvas {
        border: 1px solid #ddd;
        border-radius: 4px;
    }
</style>

<!-- Header -->
<div id="includedContent"></div>
<script> 
    $(function(){
      $("#includedContent").load("header.html"); 
    });
</script> 

<dt-article>

  <h1>Generative Adversarial Networks</h1>
  <h2>Learning to Create by Learning to Deceive</h2>
  <hr>

  <!-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• -->
  <!--  SECTION 1 â€“ Motivation                                -->
  <!-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• -->

  <h2>From Blurry Reconstructions to Sharp Fakes</h2>
  <p>
    In the previous chapter, we saw how VAEs learn to generate by compressing data into a smooth latent space and reconstructing it. The result is principled and mathematically elegantâ€”but often <strong>blurry</strong>. The pixel-wise reconstruction loss averages over uncertainties instead of committing to sharp details.
  </p>
  <p>
    What if, instead of measuring generation quality with a fixed formula, we trained a <em>second</em> neural network whose sole purpose is to judge how realistic the output looks? The generator would then learn not from a static loss function, but from a <strong>living, adaptive critic</strong> that keeps raising the bar.
  </p>
  <p>
    This is the key idea behind <strong>Generative Adversarial Networks (GANs)</strong>, introduced by Ian Goodfellow et al. in 2014. GANs reframe generation as a two-player game and, in doing so, produce images of astonishing sharpness.
  </p>

  <!-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• -->
  <!--  SECTION 2 â€“ The Counterfeiter Analogy                 -->
  <!-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• -->

  <h2>The Counterfeiter and the Detective</h2>
  <p>
    The most common analogy for GANs is a counterfeiting game:
  </p>
  <ul>
    <li><strong>The Generator $G$</strong> is a counterfeiter who produces fake banknotes. It starts with no knowledge of what real money looks like.</li>
    <li><strong>The Discriminator $D$</strong> is a detective who examines banknotes and must decide: <em>real</em> or <em>fake</em>?</li>
  </ul>
  <p>
    At first, the counterfeiter produces crude fakes, and the detective catches them easily. But every time the detective provides feedback ("this is fake becauseâ€¦"), the counterfeiter improves. In turn, the detective must sharpen its own skills. Over time, the counterfeiter becomes so good that the detective can no longer tell the differenceâ€”at which point the fakes are indistinguishable from real banknotes.
  </p>

  <div class="intuition-box">
    The Generator never sees the real data directly. It only receives a signal: "the Discriminator thought your output was fake." All learning happens through this adversarial gradient. This is fundamentally different from a VAE, where the decoder is directly compared to the input pixel-by-pixel.
  </div>

  <!-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• -->
  <!--  SECTION 3 â€“ Architecture                              -->
  <!-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• -->

  <h2>The Architecture in Detail</h2>

  <h3>1. The Generator $G(z)$</h3>
  <p>
    The Generator is a neural network (often a transposed convolutional network for images) that maps a random noise vector $z \sim p_z(z)$ â€” typically drawn from a standard Gaussian or uniform distribution â€” to a synthetic data sample $\tilde{x} = G(z)$.
  </p>
  <p>
    Unlike the VAE decoder, the Generator has <strong>no reconstruction target</strong>. It doesn't try to reproduce any specific image. Instead, it learns to produce outputs that <em>in aggregate</em> match the statistical properties of the real data distribution, as judged by the Discriminator.
  </p>

  <h3>2. The Discriminator $D(x)$</h3>
  <p>
    The Discriminator is a binary classifier. It takes any image $x$ as input and outputs a single scalar $D(x) \in [0, 1]$, representing the probability that $x$ came from the real dataset rather than from the Generator.
  </p>
  <ul>
    <li>$D(x) \to 1$: the Discriminator is confident $x$ is <strong>real</strong></li>
    <li>$D(x) \to 0$: the Discriminator is confident $x$ is <strong>fake</strong></li>
  </ul>

  <h3>3. The Training Loop</h3>
  <p>
    Training alternates between two phases:
  </p>
  <ol>
    <li>
      <strong>Train the Discriminator:</strong> Show it a batch of real images (label = 1) and a batch of fake images from $G$ (label = 0). Update $D$ to classify them correctly.
    </li>
    <li>
      <strong>Train the Generator:</strong> Generate a batch of fake images, feed them to $D$, and update $G$ to <em>maximize</em> the probability that $D$ misclassifies them as real.
    </li>
  </ol>
  <p>
    This alternation is crucial. If you train one network too much relative to the other, the balance collapsesâ€”a point we'll revisit when discussing training instabilities.
  </p>

  <!-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• -->
  <!--  SECTION 4 â€“ Mathematics                               -->
  <!-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• -->

  <h2>The Mathematics: The Minimax Game</h2>
  <p>
    The GAN objective is formulated as a <strong>minimax game</strong>. The Discriminator maximizes the value function $V$; the Generator minimizes it:
  </p>
  <p>
    $$\boxed{\min_G \max_D \; V(D, G) = \mathbb{E}_{x \sim p_{\text{data}}(x)}[\log D(x)] + \mathbb{E}_{z \sim p_z(z)}[\log(1 - D(G(z)))]}$$
  </p>
  <p>
    Let's unpack each term to build intuition.
  </p>

  <h3>The Discriminator's Perspective (maximizing $V$)</h3>
  <p>
    The Discriminator wants to assign high probability to real data and low probability to fake data:
  </p>
  <ul>
    <li>
      $\mathbb{E}_{x \sim p_{\text{data}}}[\log D(x)]$: For real samples, $D$ wants $D(x) \to 1$. Then $\log D(x) \to \log 1 = 0$, the maximum value. If $D$ makes a mistake and outputs $D(x) \to 0$, then $\log D(x) \to -\infty$ â€” a severe penalty.
    </li>
    <li>
      $\mathbb{E}_{z \sim p_z}[\log(1 - D(G(z)))]$: For fake samples, $D$ wants $D(G(z)) \to 0$, so $\log(1 - 0) = \log 1 = 0$. If $D$ is fooled ($D(G(z)) \to 1$), then $\log(1-1) \to -\infty$.
    </li>
  </ul>
  <p>
    In summary, maximizing $V$ with respect to $D$ is equivalent to training a binary classifier with the standard cross-entropy loss.
  </p>

  <h3>The Generator's Perspective (minimizing $V$)</h3>
  <p>
    The Generator only controls the second term (the first term doesn't depend on $G$):
  </p>
  <p>
    $$\min_G \; \mathbb{E}_{z \sim p_z}[\log(1 - D(G(z)))]$$
  </p>
  <p>
    The Generator wants $D(G(z)) \to 1$ (fool the Discriminator), which makes $\log(1 - D(G(z))) \to -\infty$, minimizing the objective.
  </p>

  <div class="intuition-box">
    Both networks are playing tug-of-war with the same rope. $D$ pulls toward perfectly separating real from fake. $G$ pulls toward making its fakes indistinguishable. The "rope" is the value function $V$: $D$ pushes it up, $G$ pushes it down.
  </div>

  <!-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• -->
  <!--  SECTION 5 â€“ Deriving the Optimal D                    -->
  <!-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• -->

  <h2>Deriving the Optimal Discriminator</h2>
  <p>
    A key theoretical result is: <strong>for a fixed Generator $G$, what is the optimal Discriminator $D^*$?</strong> This derivation is important because it lets us prove what happens when the whole system converges.
  </p>

  <div class="derivation-step">
    <div class="step-label">Step 1 â€” Write $V$ as a single integral</div>
    <p>
      Let $p_g$ denote the distribution of samples produced by $G$ (i.e., push-forward of $p_z$ through $G$). We can rewrite the expectation over $z$ as an expectation over $p_g$:
    </p>
    <p>
      $$V(D, G) = \int_x p_{\text{data}}(x)\, \log D(x)\, dx + \int_x p_g(x)\, \log(1 - D(x))\, dx$$
    </p>
    <p>
      $$= \int_x \Big[ p_{\text{data}}(x)\, \log D(x) + p_g(x)\, \log(1 - D(x)) \Big] dx$$
    </p>
  </div>

  <div class="derivation-step">
    <div class="step-label">Step 2 â€” Optimize pointwise</div>
    <p>
      For each $x$, we want to find the $D(x) \in [0, 1]$ that maximizes $f(y) = a \log y + b \log(1 - y)$, where $a = p_{\text{data}}(x)$ and $b = p_g(x)$.
    </p>
    <p>
      Taking the derivative and setting it to zero:
    </p>
    <p>
      $$\frac{d f}{d y} = \frac{a}{y} - \frac{b}{1 - y} = 0 \quad \Longrightarrow \quad y^* = \frac{a}{a + b}$$
    </p>
  </div>

  <div class="derivation-step">
    <div class="step-label">Step 3 â€” The optimal Discriminator</div>
    <p>
      Substituting back:
    </p>
    <p>
      $$\boxed{D^*(x) = \frac{p_{\text{data}}(x)}{p_{\text{data}}(x) + p_g(x)}}$$
    </p>
    <p>
      This is remarkably intuitive: the optimal Discriminator outputs the <em>proportion</em> of real data at each point. If $p_g = p_{\text{data}}$, then $D^*(x) = \frac{1}{2}$ everywhere â€” the Discriminator is reduced to guessing.
    </p>
  </div>

  <div class="intuition-box">
    At the Nash equilibrium, where $G$ has perfectly learned the data distribution, the optimal Discriminator outputs $\frac{1}{2}$ for every input â€” it genuinely cannot tell real from fake. The "counterfeiter" has won.
  </div>

  <!-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• -->
  <!--  SECTION 6 â€“ Connection to JS Divergence               -->
  <!-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• -->

  <h2>What Is the Generator Actually Minimizing?</h2>
  <p>
    If we substitute $D^*$ back into the value function, we can discover what the Generator is <em>really</em> optimizing:
  </p>

  <div class="derivation-step">
    <div class="step-label">Step 4 â€” Substitute $D^*$ into $V$</div>
    <p>
      $$V(D^*, G) = \int_x p_{\text{data}}(x)\, \log \frac{p_{\text{data}}(x)}{p_{\text{data}}(x) + p_g(x)}\, dx + \int_x p_g(x)\, \log \frac{p_g(x)}{p_{\text{data}}(x) + p_g(x)}\, dx$$
    </p>
  </div>

  <div class="derivation-step">
    <div class="step-label">Step 5 â€” Rewrite in terms of known divergences</div>
    <p>
      Let $m(x) = \frac{1}{2}(p_{\text{data}}(x) + p_g(x))$ be the mixture distribution. Then:
    </p>
    <p>
      $$V(D^*, G) = \int_x p_{\text{data}}(x)\, \log \frac{p_{\text{data}}(x)}{2\, m(x)}\, dx + \int_x p_g(x)\, \log \frac{p_g(x)}{2\, m(x)}\, dx$$
    </p>
    <p>
      $$= D_{\text{KL}}(p_{\text{data}} \| m) + D_{\text{KL}}(p_g \| m) - 2\log 2$$
    </p>
  </div>

  <div class="derivation-step">
    <div class="step-label">Step 6 â€” The Jensen-Shannon Divergence</div>
    <p>
      The sum of the two KL terms is precisely twice the <strong>Jensen-Shannon Divergence</strong>:
    </p>
    <p>
      $$\boxed{V(D^*, G) = 2\, D_{\text{JS}}(p_{\text{data}} \| p_g) - 2\log 2}$$
    </p>
    <p>
      Since $D_{\text{JS}} \geq 0$ and equals zero <em>only</em> when $p_g = p_{\text{data}}$, the global minimum of the Generator's objective is achieved precisely when the generated distribution matches the real data distribution. The value at this minimum is $-2\log 2 \approx -1.386$.
    </p>
  </div>

  <div class="intuition-box">
    This is the deepest theoretical result about GANs: the adversarial game implicitly minimizes the Jensen-Shannon divergence between the real and generated distributions. This is a symmetric, bounded divergence â€” unlike the KL divergence used in VAEs â€” which gives GANs different (and in some ways nicer) theoretical properties.
  </div>

  <!-- Interactive: Adversarial Training -->
  <h2>Interactive: The Adversarial Dance</h2>
  <p>
    Below, we simulate the GAN training process in 1D. The <strong style="color:green">green curve</strong> is the real data distribution $p_{\text{data}}$. The <strong style="color:red">red curve</strong> is the Generator's distribution $p_g$. The <strong style="color:blue">blue dashed line</strong> is the Discriminator's output $D(x)$ (high = "probably real", low = "probably fake").
  </p>
  <p>
    Alternate between training $D$ and $G$ manually, or press <strong>Auto-Train</strong> to watch the adversarial dance unfold.
  </p>

  <div class="interactive-container" id="danceContainer">
    <h4>Interactive Â· The Adversarial Training Loop</h4>
    <div class="legend">
      <span><div class="dot" style="background:#EBC043"></div> Real Data $p_{\text{data}}$</span>
      <span><div class="dot" style="background:#c4922a"></div> Generator $p_g$</span>
      <span><div class="dot" style="background:#1a1a2e"></div> Discriminator $D(x)$</span>
    </div>
    <div class="canvas-wrapper">
      <canvas id="ganCanvas" width="620" height="300"></canvas>
    </div>
    <div class="btn-row">
      <button class="train-btn btn-d" onclick="GAN.stepD()">Train D</button>
      <button class="train-btn btn-g" onclick="GAN.stepG()">Train G</button>
      <button class="train-btn btn-play" id="autoBtn" onclick="GAN.toggleAuto()">Auto-Train</button>
      <button class="train-btn btn-reset" onclick="GAN.reset()">Reset</button>
      <span class="epoch-display" id="epochDisplay">Epoch 0</span>
    </div>
    <div class="status-text" id="statusText">Click "Train D" to begin, or hit "Auto-Train".</div>
  </div>

  <!-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• -->
  <!--  Interactive: Optimal Discriminator                     -->
  <!-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• -->

  <h2>Interactive: The Optimal Discriminator</h2>
  <p>
    We showed that $D^*(x) = \frac{p_{\text{data}}(x)}{p_{\text{data}}(x) + p_g(x)}$. Use the slider below to move the Generator's distribution and observe how the optimal Discriminator adapts. When the two distributions overlap perfectly, $D^*$ becomes a flat line at $0.5$.
  </p>

  <div class="interactive-container" id="optDContainer">
    <h4>Interactive Â· Optimal Discriminator $D^*(x)$</h4>
    <div class="slider-row">
      <label>Generator mean:</label>
      <input type="range" id="optDSlider" min="50" max="450" step="5" value="150">
      <span class="val" id="optDVal">150</span>
    </div>
    <div class="canvas-wrapper">
      <canvas id="optDCanvas" width="520" height="260"></canvas>
    </div>
    <div class="control-panel">
      <p>The green curve is $p_{\text{data}}$ (fixed). The red curve is $p_g$ (movable). The blue curve is $D^*(x) = \frac{p_{\text{data}}}{p_{\text{data}} + p_g}$. Slide $p_g$ on top of $p_{\text{data}}$ to see $D^*$ flatten to $0.5$.</p>
    </div>
  </div>

  <!-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• -->
  <!--  Interactive: Mode Collapse                             -->
  <!-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• -->

  <h2>Training Challenges</h2>

  <h3>Mode Collapse</h3>
  <p>
    One of the most notorious GAN failure modes is <strong>mode collapse</strong>: the Generator discovers a single output (or a small set of outputs) that reliably fools the Discriminator, and stops exploring the rest of the data distribution. In a dataset of faces, for example, the Generator might produce the same face over and over.
  </p>
  <p>
    This happens because the Generator's gradient points toward the closest "safe zone" in the Discriminator's landscape. Once it finds one, there is no pressure to diversify.
  </p>

  <div class="interactive-container" id="modeCollapseContainer">
    <h4>Interactive Â· Mode Collapse Demonstration</h4>
    <div class="slider-row">
      <label>Diversity pressure:</label>
      <input type="range" id="diversitySlider" min="0" max="100" step="1" value="100">
      <span class="val" id="diversityVal">100%</span>
    </div>
    <div class="canvas-wrapper">
      <canvas id="modeCanvas" width="520" height="260"></canvas>
    </div>
    <div class="control-panel">
      <p>The real data (green) has three modes. At 100% diversity the Generator (red) covers all three. Drag the slider down to simulate mode collapse: the Generator collapses onto fewer and fewer modes.</p>
    </div>
  </div>

  <h3>Vanishing Gradients</h3>
  <p>
    If the Discriminator becomes too strong too early, $D(G(z)) \approx 0$ for all generated samples. The Generator's loss $\log(1 - D(G(z))) \approx \log 1 = 0$ is nearly flat, providing <strong>vanishing gradients</strong> â€” the Generator receives almost no signal for improvement.
  </p>
  <p>
    A practical workaround is to replace the Generator's objective. Instead of minimizing $\log(1 - D(G(z)))$, we maximize $\log D(G(z))$:
  </p>
  <p>
    $$\max_G \; \mathbb{E}_{z \sim p_z}[\log D(G(z))]$$
  </p>
  <p>
    This provides stronger gradients early in training when $D(G(z))$ is small. Technically it changes the divergence being minimized, but in practice it dramatically stabilizes early training.
  </p>

  <h3>Training Balance</h3>
  <p>
    Successful GAN training requires careful balance:
  </p>
  <ul>
    <li><strong>$D$ too strong:</strong> $G$ gets vanishing gradients.</li>
    <li><strong>$D$ too weak:</strong> $G$ gets uninformative feedback ("everything looks real to me").</li>
    <li><strong>$G$ too strong relative to $D$:</strong> The loss saturates, providing no improvement signal.</li>
  </ul>
  <p>
    In practice, this balance is maintained through careful hyperparameter tuning, alternating update schedules, and architectural innovations (spectral normalization, progressive growing, etc.).
  </p>

  <div class="intuition-box">
    Training a GAN is like teaching a student by only telling them "wrong" without telling them <em>why</em>. If the teacher (Discriminator) is too harsh, the student gives up. If the teacher is too lenient, the student never learns. The ideal is a teacher who is just slightly aheadâ€”always challenging, but never overwhelming.
  </div>

  <!-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• -->
  <!--  Interactive: D vs G Loss                               -->
  <!-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• -->

  <h2>Interactive: Generator vs. Discriminator Loss</h2>
  <p>
    The plot below simulates the loss trajectories during training. The key question is: <em>do both losses stabilize?</em> Use the balance slider to see how training dynamics change when one network dominates.
  </p>

  <div class="interactive-container" id="lossContainer">
    <h4>Interactive Â· Training Loss Dynamics</h4>
    <div class="slider-row">
      <label>D / G balance:</label>
      <input type="range" id="balanceSlider" min="-3" max="3" step="0.1" value="0">
      <span class="val" id="balanceVal">Balanced</span>
    </div>
    <div class="canvas-wrapper">
      <canvas id="lossCanvas" width="560" height="260"></canvas>
    </div>
    <div class="control-panel">
      <p>Center = balanced training (both converge). Left = D dominates (G loss stays high). Right = G dominates (D can't keep up). Watch how only the balanced regime leads to a stable equilibrium.</p>
    </div>
  </div>

  <!-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• -->
  <!--  SECTION â€“ Summary                                      -->
  <!-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• -->

  <h2>Summary &amp; Limitations</h2>
  <p>
    GANs introduced a paradigm shift in generative modeling:
  </p>
  <ul>
    <li>They produce <strong>sharp, high-fidelity images</strong> by optimizing an adversarial signal rather than pixel-wise loss.</li>
    <li>The theoretical framework shows that the Generator implicitly minimizes the <strong>Jensen-Shannon divergence</strong> between real and generated distributions.</li>
    <li>The optimal Discriminator $D^* = \frac{p_{\text{data}}}{p_{\text{data}} + p_g}$ provides a clean theoretical target.</li>
  </ul>
  <p>
    But GANs come with significant practical challenges:
  </p>
  <ul>
    <li><strong>Mode collapse:</strong> The Generator may produce limited variety.</li>
    <li><strong>Training instability:</strong> The minimax optimization is fundamentally harder than standard loss minimization.</li>
    <li><strong>No explicit density:</strong> Unlike VAEs, GANs do not model $p(x)$ directly, so you cannot compute likelihoods.</li>
    <li><strong>No encoder:</strong> Standard GANs don't provide a way to map data back to latent space (though BiGANs and ALI address this).</li>
  </ul>
  <p>
    The quest for sharp outputs <em>with</em> stable training led to the development of <a href="pixel-diffusion.html"><strong>Diffusion Models</strong></a>, which achieve state-of-the-art image quality through a completely different mechanism: iteratively denoising random noise.
  </p>

  <!-- â”€â”€ References â”€â”€ -->
  <h2>References</h2>
  <ol class="references-list">
    <li>Goodfellow, I. et al. (2014). <em>Generative Adversarial Nets.</em> NeurIPS 2014. <a href="https://arxiv.org/abs/1406.2661" target="_blank">arXiv:1406.2661</a></li>
    <li>Arjovsky, M., Chintala, S. &amp; Bottou, L. (2017). <em>Wasserstein GAN.</em> <a href="https://arxiv.org/abs/1701.07875" target="_blank">arXiv:1701.07875</a></li>
    <li>Brock, A., Donahue, J. &amp; Simonyan, K. (2019). <em>Large Scale GAN Training for High Fidelity Natural Image Synthesis.</em> <a href="https://arxiv.org/abs/1809.11096" target="_blank">arXiv:1809.11096</a></li>
  </ol>

  <!-- â”€â”€ Chapter Navigation â”€â”€ -->
  <div class="chapter-nav">
    <a href="vae.html">
      <span class="nav-label">â† Previous</span>
      <span class="nav-title">Variational Autoencoders</span>
    </a>
    <a href="pixel-diffusion.html" class="next">
      <span class="nav-label">Next Chapter â†’</span>
      <span class="nav-title">Pixel-Space Diffusion</span>
    </a>
  </div>

</dt-article>

<!-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• -->
<!--  ALL INTERACTIVE SCRIPTS                                   -->
<!-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• -->
<script>
// â”€â”€â”€ Utility â”€â”€â”€
function gaussPDF(x, mu, sigma) {
    return Math.exp(-0.5 * ((x - mu) / sigma) ** 2) / (sigma * Math.sqrt(2 * Math.PI));
}

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// 1. Adversarial Dance (enhanced)
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
const GAN = (function() {
    const canvas = document.getElementById('ganCanvas');
    const ctx = canvas.getContext('2d');
    const statusText = document.getElementById('statusText');
    const epochDisplay = document.getElementById('epochDisplay');
    const autoBtn = document.getElementById('autoBtn');
    const W = 620, H = 300;

    let realMean = 400, realStd = 45;
    let fakeMean = 120, fakeStd = 50;
    let targetFake = 120, targetFakeStd = 50;
    let boundary = 260, targetBoundary = 260;
    let epoch = 0;
    let autoId = null;

    function sigmoid(x, b, sharpness) {
        return 1 / (1 + Math.exp(-sharpness * (x - b)));
    }

    function draw() {
        ctx.clearRect(0, 0, W, H);
        fakeMean += (targetFake - fakeMean) * 0.08;
        fakeStd += (targetFakeStd - fakeStd) * 0.08;
        boundary += (targetBoundary - boundary) * 0.08;

        // Sharpness of discriminator increases with training
        const sharpness = 0.03 + epoch * 0.003;

        // Background grid
        ctx.strokeStyle = '#eee';
        ctx.lineWidth = 1;
        for (let y = 50; y < H; y += 50) {
            ctx.beginPath(); ctx.moveTo(0, y); ctx.lineTo(W, y); ctx.stroke();
        }

        // Real (green)
        ctx.beginPath();
        ctx.strokeStyle = '#22c55e';
        ctx.lineWidth = 3;
        for (let x = 0; x < W; x++) {
            const y = gaussPDF(x, realMean, realStd) * 9000;
            if (x === 0) ctx.moveTo(x, H - y); else ctx.lineTo(x, H - y);
        }
        ctx.stroke();
        // Fill
        ctx.globalAlpha = 0.1;
        ctx.lineTo(W, H); ctx.lineTo(0, H); ctx.closePath();
        ctx.fillStyle = '#22c55e'; ctx.fill();
        ctx.globalAlpha = 1;

        // Fake (red)
        ctx.beginPath();
        ctx.strokeStyle = '#ef4444';
        ctx.lineWidth = 3;
        for (let x = 0; x < W; x++) {
            const y = gaussPDF(x, fakeMean, fakeStd) * 9000;
            if (x === 0) ctx.moveTo(x, H - y); else ctx.lineTo(x, H - y);
        }
        ctx.stroke();
        ctx.globalAlpha = 0.1;
        ctx.lineTo(W, H); ctx.lineTo(0, H); ctx.closePath();
        ctx.fillStyle = '#ef4444'; ctx.fill();
        ctx.globalAlpha = 1;

        // Discriminator (navy dashed)
        ctx.beginPath();
        ctx.strokeStyle = '#1a1a2e';
        ctx.lineWidth = 2;
        ctx.setLineDash([5, 4]);
        for (let x = 0; x < W; x++) {
            const prob = sigmoid(x, boundary, sharpness);
            const y = prob * (H * 0.75);
            if (x === 0) ctx.moveTo(x, H - y - 15); else ctx.lineTo(x, H - y - 15);
        }
        ctx.stroke();
        ctx.setLineDash([]);

        // D = 0.5 reference line
        ctx.strokeStyle = '#ddd';
        ctx.lineWidth = 1;
        ctx.setLineDash([2, 4]);
        const halfY = H - 0.5 * (H * 0.75) - 15;
        ctx.beginPath(); ctx.moveTo(0, halfY); ctx.lineTo(W, halfY); ctx.stroke();
        ctx.setLineDash([]);
        ctx.fillStyle = '#bbb'; ctx.font = '10px sans-serif';
        ctx.fillText('D = 0.5', 4, halfY - 4);

        requestAnimationFrame(draw);
    }

    function stepD() {
        targetBoundary = (realMean + targetFake) / 2;
        epoch++;
        epochDisplay.textContent = 'Epoch ' + epoch;
        statusText.textContent = 'D adapts: boundary moves between real and fake distributions.';
    }

    function stepG() {
        if (Math.abs(targetFake - realMean) < 8) {
            statusText.textContent = 'âœ“ Converged! G â‰ˆ p_data â€” the Discriminator is reduced to guessing.';
            stopAuto();
            return;
        }
        const step = Math.max(15, (realMean - targetFake) * 0.2);
        targetFake += step;
        targetFakeStd += (realStd - targetFakeStd) * 0.15;
        epoch++;
        epochDisplay.textContent = 'Epoch ' + epoch;
        statusText.textContent = 'G adapts: moves toward region where D says "real".';
    }

    let autoRunning = false;
    function toggleAuto() {
        if (autoRunning) { stopAuto(); return; }
        autoRunning = true;
        autoBtn.textContent = 'Stop';
        autoBtn.className = 'train-btn btn-stop';
        autoStep();
    }
    function autoStep() {
        if (!autoRunning) return;
        stepD();
        setTimeout(() => {
            if (!autoRunning) return;
            stepG();
            autoId = setTimeout(autoStep, 400);
        }, 200);
    }
    function stopAuto() {
        autoRunning = false;
        clearTimeout(autoId);
        autoBtn.textContent = 'Auto-Train';
        autoBtn.className = 'train-btn btn-play';
    }

    function reset() {
        stopAuto();
        targetFake = 120; fakeMean = 120;
        targetFakeStd = 50; fakeStd = 50;
        targetBoundary = 260; boundary = 260;
        epoch = 0;
        epochDisplay.textContent = 'Epoch 0';
        statusText.textContent = 'Simulation reset.';
    }

    draw();
    return { stepD, stepG, toggleAuto, reset };
})();

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// 2. Optimal Discriminator
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
(function() {
    const slider = document.getElementById('optDSlider');
    const valSpan = document.getElementById('optDVal');
    const canvas = document.getElementById('optDCanvas');
    if (!canvas) return;
    const ctx = canvas.getContext('2d');
    const W = 520, H = 260;
    const realMean = 350, std = 50;

    function draw() {
        const gMean = parseFloat(slider.value);
        valSpan.textContent = gMean;
        ctx.clearRect(0, 0, W, H);

        // grid
        ctx.strokeStyle = '#f0f0f0'; ctx.lineWidth = 1;
        for (let y = 40; y < H; y += 40) { ctx.beginPath(); ctx.moveTo(0,y); ctx.lineTo(W,y); ctx.stroke(); }

        const scale = 7000;

        // p_data (green)
        ctx.beginPath(); ctx.strokeStyle = '#22c55e'; ctx.lineWidth = 2.5;
        for (let x = 0; x < W; x++) {
            const y = gaussPDF(x, realMean, std) * scale;
            if (x === 0) ctx.moveTo(x, H - y); else ctx.lineTo(x, H - y);
        }
        ctx.stroke();

        // p_g (red)
        ctx.beginPath(); ctx.strokeStyle = '#ef4444'; ctx.lineWidth = 2.5;
        for (let x = 0; x < W; x++) {
            const y = gaussPDF(x, gMean, std) * scale;
            if (x === 0) ctx.moveTo(x, H - y); else ctx.lineTo(x, H - y);
        }
        ctx.stroke();

        // D*(x) (navy)
        ctx.beginPath(); ctx.strokeStyle = '#1a1a2e'; ctx.lineWidth = 2;
        ctx.setLineDash([5, 3]);
        for (let x = 0; x < W; x++) {
            const pReal = gaussPDF(x, realMean, std);
            const pFake = gaussPDF(x, gMean, std);
            const dStar = (pReal + pFake) > 1e-10 ? pReal / (pReal + pFake) : 0.5;
            const y = dStar * (H * 0.7);
            if (x === 0) ctx.moveTo(x, H - y - 10); else ctx.lineTo(x, H - y - 10);
        }
        ctx.stroke();
        ctx.setLineDash([]);

        // D = 0.5 ref
        const halfY = H - 0.5 * (H * 0.7) - 10;
        ctx.strokeStyle = '#ddd'; ctx.lineWidth = 1; ctx.setLineDash([2, 4]);
        ctx.beginPath(); ctx.moveTo(0, halfY); ctx.lineTo(W, halfY); ctx.stroke();
        ctx.setLineDash([]);
        ctx.fillStyle = '#bbb'; ctx.font = '10px sans-serif'; ctx.fillText('D* = 0.5', 4, halfY - 4);
    }

    slider.addEventListener('input', draw);
    draw();
})();

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// 3. Mode Collapse
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
(function() {
    const slider = document.getElementById('diversitySlider');
    const valSpan = document.getElementById('diversityVal');
    const canvas = document.getElementById('modeCanvas');
    if (!canvas) return;
    const ctx = canvas.getContext('2d');
    const W = 520, H = 260;

    const modes = [
        { mean: 130, std: 30 },
        { mean: 260, std: 30 },
        { mean: 390, std: 30 }
    ];

    function draw() {
        const diversity = parseFloat(slider.value) / 100;
        valSpan.textContent = Math.round(diversity * 100) + '%';
        ctx.clearRect(0, 0, W, H);

        // grid
        ctx.strokeStyle = '#f0f0f0'; ctx.lineWidth = 1;
        for (let y = 40; y < H; y += 40) { ctx.beginPath(); ctx.moveTo(0,y); ctx.lineTo(W,y); ctx.stroke(); }

        const scale = 4000;

        // Real data (3 modes, green)
        ctx.beginPath(); ctx.strokeStyle = '#22c55e'; ctx.lineWidth = 2.5;
        for (let x = 0; x < W; x++) {
            let y = 0;
            modes.forEach(m => { y += gaussPDF(x, m.mean, m.std); });
            y = (y / 3) * scale;
            if (x === 0) ctx.moveTo(x, H - y); else ctx.lineTo(x, H - y);
        }
        ctx.stroke();
        ctx.globalAlpha = 0.08;
        ctx.lineTo(W, H); ctx.lineTo(0, H); ctx.closePath();
        ctx.fillStyle = '#22c55e'; ctx.fill();
        ctx.globalAlpha = 1;

        // Generator (red) â€” diversity controls how many modes are covered
        // At diversity=1: cover all 3 equally. At diversity=0: collapse to mode 1 only.
        const weights = [
            1,
            Math.pow(diversity, 1.5),
            Math.pow(diversity, 2.5)
        ];
        const totalW = weights.reduce((a, b) => a + b, 0);

        ctx.beginPath(); ctx.strokeStyle = '#ef4444'; ctx.lineWidth = 2.5;
        for (let x = 0; x < W; x++) {
            let y = 0;
            modes.forEach((m, i) => {
                const gStd = m.std * (0.6 + diversity * 0.4);
                y += gaussPDF(x, m.mean, gStd) * weights[i] / totalW;
            });
            y = (y / 3) * scale * (1 + (1 - diversity) * 2);
            if (x === 0) ctx.moveTo(x, H - y); else ctx.lineTo(x, H - y);
        }
        ctx.stroke();
        ctx.globalAlpha = 0.08;
        ctx.lineTo(W, H); ctx.lineTo(0, H); ctx.closePath();
        ctx.fillStyle = '#ef4444'; ctx.fill();
        ctx.globalAlpha = 1;

        // Label
        ctx.fillStyle = '#666'; ctx.font = '12px sans-serif'; ctx.textAlign = 'center';
        if (diversity < 0.2) ctx.fillText('âš  Mode Collapse: Generator covers only 1 mode', W / 2, 18);
        else if (diversity < 0.6) ctx.fillText('Partial collapse: some modes underrepresented', W / 2, 18);
        else ctx.fillText('Healthy training: all modes covered', W / 2, 18);
    }

    slider.addEventListener('input', draw);
    draw();
})();

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// 4. Training Loss Dynamics
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
(function() {
    const slider = document.getElementById('balanceSlider');
    const valSpan = document.getElementById('balanceVal');
    const canvas = document.getElementById('lossCanvas');
    if (!canvas) return;
    const ctx = canvas.getContext('2d');
    const W = 560, H = 260;

    function draw() {
        const balance = parseFloat(slider.value); // -3 (D dominates) to +3 (G dominates)
        if (balance < -1) valSpan.textContent = 'D dominates';
        else if (balance > 1) valSpan.textContent = 'G dominates';
        else valSpan.textContent = 'Balanced';

        ctx.clearRect(0, 0, W, H);
        const pad = 40;
        const pw = W - 2 * pad;
        const ph = H - 2 * pad;

        // Axes
        ctx.strokeStyle = '#ccc'; ctx.lineWidth = 1;
        ctx.beginPath();
        ctx.moveTo(pad, H - pad); ctx.lineTo(W - pad, H - pad);
        ctx.moveTo(pad, H - pad); ctx.lineTo(pad, pad);
        ctx.stroke();
        ctx.fillStyle = '#999'; ctx.font = '11px sans-serif';
        ctx.textAlign = 'center';
        ctx.fillText('Training Steps', W / 2, H - 8);
        ctx.save();
        ctx.translate(12, H / 2);
        ctx.rotate(-Math.PI / 2);
        ctx.fillText('Loss', 0, 0);
        ctx.restore();

        const steps = 200;

        // D loss (navy)
        ctx.beginPath(); ctx.strokeStyle = '#1a1a2e'; ctx.lineWidth = 2;
        for (let i = 0; i < steps; i++) {
            const t = i / steps;
            // D loss decays, but if balance is positive (G too strong), D loss stays high
            let dLoss;
            if (balance < 0) {
                // D dominates: D loss drops quickly
                dLoss = 0.7 * Math.exp(-t * (3 - balance)) + 0.05 + Math.sin(t * 40) * 0.02;
            } else {
                // Balanced or G dominates
                dLoss = 0.7 * Math.exp(-t * 3) + 0.05 + balance * 0.12 * (1 - Math.exp(-t * 2)) + Math.sin(t * 40) * 0.02;
            }
            dLoss = Math.max(0.02, Math.min(1, dLoss));
            const x = pad + t * pw;
            const y = (H - pad) - dLoss * ph;
            if (i === 0) ctx.moveTo(x, y); else ctx.lineTo(x, y);
        }
        ctx.stroke();

        // G loss (red)
        ctx.beginPath(); ctx.strokeStyle = '#ef4444'; ctx.lineWidth = 2;
        for (let i = 0; i < steps; i++) {
            const t = i / steps;
            let gLoss;
            if (balance < 0) {
                // D dominates: G loss stays high (vanishing gradients)
                gLoss = 0.8 - 0.1 * t + Math.abs(balance) * 0.1 * (1 - Math.exp(-t * 1.5)) + Math.sin(t * 35 + 1) * 0.02;
            } else if (balance > 1) {
                // G dominates: G loss drops fast
                gLoss = 0.8 * Math.exp(-t * (2 + balance)) + 0.05 + Math.sin(t * 35 + 1) * 0.02;
            } else {
                // Balanced
                gLoss = 0.8 * Math.exp(-t * 2.5) + 0.08 + Math.sin(t * 35 + 1) * 0.02;
            }
            gLoss = Math.max(0.02, Math.min(1, gLoss));
            const x = pad + t * pw;
            const y = (H - pad) - gLoss * ph;
            if (i === 0) ctx.moveTo(x, y); else ctx.lineTo(x, y);
        }
        ctx.stroke();

        // Legend
        ctx.fillStyle = '#1a1a2e'; ctx.font = 'bold 12px sans-serif';
        ctx.textAlign = 'left';
        ctx.fillText('D Loss', pad + 8, pad + 14);
        ctx.fillStyle = '#c4922a';
        ctx.fillText('G Loss', pad + 8, pad + 30);

        // Equilibrium line
        if (Math.abs(balance) < 1.2) {
            ctx.strokeStyle = '#ddd'; ctx.lineWidth = 1; ctx.setLineDash([3, 3]);
            const eqY = (H - pad) - 0.12 * ph;
            ctx.beginPath(); ctx.moveTo(pad, eqY); ctx.lineTo(W - pad, eqY); ctx.stroke();
            ctx.setLineDash([]);
            ctx.fillStyle = '#bbb'; ctx.font = '10px sans-serif';
            ctx.fillText('equilibrium', W - pad - 56, eqY - 4);
        }
    }

    slider.addEventListener('input', draw);
    draw();
})();
</script>

<div id="includedFooter"></div>
<script>$(function(){ $("#includedFooter").load("footer.html"); });</script>
<script src="shared.js"></script>
